# AI & 기계학습 기초 1 
AI와 ML은 무엇인가?

**학습목표**

- AI, ML, DL 의 정의 및 관계를 학습
- 데이터 , 가설공간, 모델의 개념 학습
- 학습(learning)의 정의 학습

### AI와 머신러닝(ML)이 내 일상에 미치는 영향

- 내 취향에 맞는 알고리즘
- 이메일이 스팸과 정상을 가려내는 방법
- 사람이 모든 규칙을 미리 코딩하지 않아도, 데이터에서 규칙을 학습해 성능을 향상한다!

## 1. AI, ML, DL의 정의

### AI (Artificial Intelligence)

- 주어진 환경, 데이터를 인지 학습 추론을 통해 목표 달성을 하도록 예측, 행동 선택, 계획하는 시스템

### ML(Machine Learning)

- AI 범주 내에서 데이터로부터 학습하여 목적을 달성하는 접근 방법론
- 언어 모델, 이미지 분류 모델, 추천 시스템 등

### DL(Deep Learning)

- ML 범주 내에서 신경망 함수를 사용한 학습 방법론

### AI - ML (ML이 아닌 AI시스템)의 예

- 규칙 기반 시스템
- 휴리스틱 기반 (최적화) 알고리

## 2. 데이터와 학습의 이해

### 2-1. 데이터 구성요소 (Feature/Label)

**Feature (피처, 특성)**

- 모델이 예측에 사용하는 입력정보
- 예측, 판단의 근거/단서

**Label (라벨, 목표값)**

- 모델이 예측하려는 정답
- 학습의 목표값

### 2-2. ML 실생활 예시

1. 유튜브 추천
    
    F : 각 영상들의 정보(장르, 크리에이터, 조회수, 좋아요 수 등 ), 사용자 정보(시청 이력, 구독 채널 등)
    
    L : 영상에 대한 사용자 피드백 (시청 여부, 좋아요 클릭 여부)
    

1. 스팸메일 분류
    
    F : 메일 제목, 발신자, 단어 빈도
    
    L : 스팸 / 정상 
    

## 3. 단일 피쳐 기반 학습

### 3-1. 1D 피쳐 기반 학습

**1D 피쳐 기반 학습 = 단일 피쳐 학습**

- Feature가 하나 일 때 머신러닝이 학습하는 가장 단순한 형태

→ 피쳐와 라벨의 관계를 잘 나타낸 함수 f는 무엇일까?


### 3-2. 모델과 가설 공간

**학습**

- 입력(피쳐) → 출력(레이블) 관계를 찾는 과정
- 평균 관계를 하나의 함수로 표현

**가설 공간**

- 관계를 표현할 수 있는 모든 후보 함수들의 모음
- 피쳐 공간과 라벨 공간 위에서 정의된 함수들의 집합

**모델** 

- 가설 공간에 속한 특정 함수 f
- 가설 공간 속 가장 fit 한 함수


### 3-3. 학습이란?

학습

- 주어진 데이터와 성능척도를 바탕으로 가설공간의 후보들 중 최적의 모델을 선택하는 과정
- 학습 전에는 점형태 → 학습 후에는 한개의 모델이 선택

## 4. 복수 피쳐 기반 학습

### 4-1. 2D 피쳐 기반 학습

어떠한 특정 surface를 사용할까 

가설공간에서 특정 함수 하나를 찾는 것 → 무한이 있는 공간에서 특정 함수를 찾는것

### 4-2. 일반적 용어 정리 및 모델 가정

- Income → 우리가 예측하려는 라벨 변수 (Y)
- Years of Education → 첫번째 피쳐 변수 → X 1로 고르기
- Seniority → 두번째 피쳐(입력 / 예측) X 2 로 표기


### 4-3. 왜 f() 를 학습하는가?

- 잘 학습된 f 가 있으면 ,새로운 입력 X = x 에서 반응 / 목표 y 를 예측할 수 있음

- 피쳐들 X의 어떤 특성이 Y를 설명하는데 중요하고, 어떤 것은 덜 중요한지 알 수 있음

- f의 복잡도에 따라 각 구성요소 X 가 y에 어떻게 영향을 미치는지 (증가/감소 방향, 민감도 등) 이해할 수 있음

---
*정리*

**AI와 ML**
- AI: 주어진 환경/데이터를 인지·학습·추론하여 목표 달성을 위한 예측·행동·선택·계획을 수행하는 시스템
- ML (Machine Learning): AI 범주 내에서 데이터를 학습하여 목표를 달성하는 방법론

**데이터의 구성 요소**
- Feature: 모델 입력 정보, 예측·판단의 근거
- Label: 모델이 예측하려는 정답, 학습의 목표

**1D 피처 기반 학습**
- Feature가 하나일 때(1차원) 수행되는 단순한 학습 형태
- Feature와 Label 사이의 관계를 함수 f로 표현하며, 실제 데이터에는 측정오차(ε) 가 포함됨

**모델과 가설 공간**
- 가설 공간 (𝓗): Feature와 Label 관계를 표현할 수 있는 함수들의 집합
- 모델 (model): 가설 공간 내 특정 함수 f

**학습**
데이터의 성능 척도를 바탕으로 가설 공간 내 후보 중 최적의 모델을 선택하는 과정

**모델 학습의 필요성**

- 예측: 새로운 입력값에 대해 Label을 추론
- 중요도 파악: 어떤 Feature가 결과에 중요한지 확인
- 해석 가능성: 각 Feature가 결과에 어떤 영향을 미치는지 이해

---

## 지도학습의 이해

- 회귀(연속값)과 분류(범주값)의 문제 정의와 출력 차이 이해
- 문제 유형에 맞는 오류/평가지표를 바르게 선택, 해석
- 학습의 목적: 테스트 성능 최대화(테스트 오류 최소화)에 대한 이해
- 오버피팅의 이해

## 1. 지도학습의 개념

### 1-1. 지도학습이란?

**데이터**

- 입력(특성)과 정답(라벨)이 쌍으로 있는 데이터 - y, x

**목표**

- 새 입력이 들어오면 정답을 잘 맞추는 규칙을 학습

**지도학습의 종류**

- 회귀 : 예측값이 숫자(가격, 점수, 온도)
- 분류: 예측값이 범주(스팸/정상, 질병 유/무)

### 1-2. 지도학습 용어

**특성 (Feature, x)**
- 예측에 쓰는 설명 변수
    - 예 ) 집값 예측 {지역, 평수, 방수, 연식}

**라벨(Label, y)**
- 맞춰야 하는 정답
    - 예 ) 집값, 스팸/정상이메일

**예측값(y heat(^))**
- 모델이 내놓은 결과(숫자 또는 범주)

**오류(Error)**
- 예측값과 라벨의 차이
- 측정오차와는 관계 없는 이야기 - 측정오차라는 것은 절대 참값이 있어야 구할 수 있는 값이기 때문에 사실상 모름

## 2. 회귀(Refression)

### 2-1. 회귀 문제

error 가 작았다 → 잘 예측했다.

### 2-2. 회귀 오류 : 평균제곱오류(MSE)

회귀를 잘했다 못했다의 기준 ?

y와 y heat 값을 잘 구하는 것

- 큰 오류를 더 크게 벌줌으로, 전체 오류 수준을 한눈에 볼 수 있음
- 제곱으로 되어있어서 미분하여 솔루션을 구하는데 용이함

### 2-3. 회귀 설명력 : R2 (결정계수)

**결정계수**

- 라벨의 분산 중에서 특성으로 설명되는 비율
- 평균만 쓰는 단순한 예측보다 얼마나 더 잘 맞추는지를 0 - 1사이로 나타낸 값

- 분자 (MSE) - 잘 되었으면 값이 작다.
- 분모 - y의 평균값으로 계산했을 때의 error 값
- 모델링을 잘 했으면 1에 가깝게 나옴 (설명력이 높다)

## 3. 분류(Classfication)

### 3-1. 분류 문제

아웃풋이 카테고리값인 것 → 분류 문제

### 3-2. 분류 정확도

정확도

- 전체 중 맞춘 비율
- 정확도만 보면 불균형 데이터(양성 1 , 음성 99)에서는 전부 음성이라 해도 정확도가 99%로 보일 수 있음

### 3-3. 혼동행렬

예측과 실제 값 사이의 관계를 행렬 형태로 표현
- TP : 실제 양성, 예측도 양성
- TN : 실제 음성, 예측도 음성
- FP : 실제는 음성인데 양성이라 함(오탐)
- FN : 실제는 양성인데 음성이라 함(누락)

**정밀도**
- 양성이라 판정한 것 중 진짜 양성의 비율
    - TP / (TP + FP)

**재현율**
- 진짜 양성 가운데 잡아낸 예측 양성 비율
    - TP / (TP + FN)

**F1-score**
- 정밀도와 재현율의 조화평균
    - F1 = 2 * (정밀도 * 재현율) / (정밀도 + 재현율)

## 4. 학습의 목적

### 4-1. 학습의 목적

학습 모델의 성능 평가는 모델이 처음 보는(학습에 사용되지 않은) 데이터로 평가

### 4-2. 오버피팅

훈련 데이터의 우연한 패팅/잡읍까지 외워버러셔 훈련에서는 잘 맞지만 테스트에서는 성능이 나빠지는 현상

현상 : 훈련 오류 급격히 낮음 , 테스트 오류 높음 / 요동

오버피팅이 안 좋은 이유

- 표본(sample) 의존, 불안정 : 훈련 데이터는 모집단의 일부 표본이라 우연한 잡음이 섞임
- 이 것에만 과하게 맞추어 학습하면 샘플 몇 개만 바귀어도 예측이 크게 흔들

### 4-3. 오버피팅에 대한 오해

**분포 변화로 인한 오류**
- 훈련 데이터 분포와 테스트 분포가 다름으로 성능이 떨어지는 현상
- 분포 변화로 인한 에러 증가는 모델이 과적합하지 않아도 발생 가능

이것만 잘 이해해도 잘 배웠다고 할 수 있을 정도로 중요함

### 4-4. 오버피팅 vs 언더피팅

**오버피팅**
모델이 너무 복잡 -> 잡음까지 학습(테스트 성능 나쁨)

**언더피팅**
모델이 너무 단순하거나 학습이 완료되지 않음 -> 중요한 패턴을 놓침(오류 큼)


-> 해결 하기 위해서는

더 많은 데이터, 테스트 데이터를 활용한 모델 선정, 교차 검증 .. 

---

**학습목표**

- 훈련 오류 vs 테스트 오류의 차이를 말하고, 왜 테스트 예측(일반화)이 목표인지 설명한다.
- 검증셋 (hold-out) , K-겹 교차검증(K-fold Cross-VValidation) 의 개념을 배운다.

## 1. 테스트 성능 평가

**훈련 오류** 

- 모델을 학습시킨 같은 데이터에 다시 적용해 계산한 오류

**테스트 오류**

- 학습에 쓰지 않은 새 관측치에 대해 모델을 적용했을 때의 평균 예측 오류

보통 훈련 오류는 테스트 오류와 다르며, 특히 훈련 오류는 테스트 오류를 (심하게) 과소평가하는 경우가 많음


가장 마지막에서 오버피팅이 일어남.

오버피팅 : 트레이닝 데이터에 너무 과적합 (너무 많이 학습함) 

가장 왼쪽에서 언더피팅이 일어남

언더피팅 : 아직 학습이 부족함

**테스트 예측 오류 계산**

- 큰 별도의 테스트 데이터셋은 현실에선 구하기 어려움
- 현실에서는 데이터 자체가 부족할 수 있음

**대안 : 재표본화를 통한 테스트 오류 추정**

- 데이터를 나눠 여러번 훈련 → 평가를 반복함
- 방법 : 검증셋, K겹 교차검증
- 별도의 테스트 데이터 없이 데이터를 더 효율적으로 사용하여 일반화 오차 수정

### 2-1. 검증셋 방법

**검증셋 (홀드아웃)방법**

- 가용 샘플을 무작위로 훈련셋 , 검증셋으로 분할
- 훈련셋으로 모델 적합, 검증셋으로 예측 후 검증 오류를 계산
- 정량반응 - MSE, 범주 반응 - 오분류율 (또는 F1-score) 측정

### 2-4. 검증셋 접근의 한계

- 어떤 표본이 훈련/검증에 들어가느냐에 따라 **검증 기반 테스트 오류 추정치가 매우 가변적**이다.
- 검증 접근에서는 훈련셋(=전체의 일부)만으로 모델을 적합하므로,
    
    전체 데이터로 학습했을 대보다 **성능이 낮게 추정 ( 즉, 테스트 오류를 과대 추정)**될 수 있음
    
    - 학습한 데이터가 적어서 ..  (학습에 데이터를 부분만 사용하기 때문)

## 3. K-겹 교차검증

- 데이터 셔플링
- 데이터 전체를 **크기가 동일한 K개의 폴드**로 무작위 분할함
- 주황은 **검증,** 나머지는 **훈련**에 사용
- K번 반복 후 **평균 오류**로 테스트 오류를 추정

### 3-3. Leave-One-Out 교차검증

훈련셋 - 관측치 하나만 제외한 나머지 전부

검증셋 - 제외한 1개 관측치

이 과정을 n번 반복해 나온 n개의 MSE 평균으로 테스트 오류를 수정

### 3-4. K-겹 교차검증 비교

두 방법의 경향과 최적 차수가 비슷하다.

테스트에서 성능이 잘 나오는지 가늠하는데 (추정) 가장 중요한 테크닉 - 교차검증 

---

## 1. 비지도 학습

- 레이블(정답) 없이 데이터의 구조 패턴 집단(잠재 서브그룹) 을 찾아내는 학습
- 대표 과제 : 군집화 , 차원 축소, 밀도 추정/이상치 탐지
- 출력: ‘정답 예측’이 아니라 구조/요약/표현

무엇을 비슷함/다름으로 볼 것인지 (거리 . 유사도 선택)

전처리(스케일 표준화 등)를 어떻게 할 것인가


## 2. 클러스터링

- 데이터 안에서 하위 집단 (클러스터)를 찾는 기법들의 총칭
- 목표 : 집단 내부는 서로 유사, 집단 간은 상이하도록 데이터 분할
- 유사/상이 정도는 도메인 맥락에 따라 정의가 달라질 수 있음
- 문제나 데이터 특성에 의존함

예시 : 마케팅 세그먼테이션

- 다수의 지표(가구 소득, 직업, 도심 거리 등)를 가진 많은 사람들에 대해 **특정 광고/상품**에 **더 반응할 하위집단**을 식별하고자 함
- **시장 세분화** 작업 자체가 **클러스터링**에 해당

두 가지 대표 클러스터링 기법

1. **K-평균** : K(클러스터수)를 미리 정해 분할
2. **계층적 군집** : K를 사전에 고정하지 않음

## 3. K-평균(K-means)클러스터링


- 적어도 하나의 군집에 속한다
- 군집간에는 교집합이 없다
- 좋은 군집화는 각각 데이터 포인터들의 분산이 작은 것이 좋은 것

### 3-2. K-means 클러스터링 알고리즘ㅈ

재배정을 해도 값이 같으면 stop 

서로 다른 초기 레이블에서 최종 분할과 목표값(패널 상단 숫자)이 달라짐 

초기화의 중요성 : 여러번 시도 권장

## 4. 계층적 군집 (Hierarchical Clustering)

### 4-1. K-means vs 계층적 군집

계층적 군집 결과 예시

- 덴드로그램에서 수평선 높이(거리) 를 기준으로 가위질하여 K개 군집을 얻음

### 4-2. 계층적 군집 알고리즘(상향식)

- 계층적 군집은 항상 클러스터들 ㄲㅣ리의 병합이다.

### 4-3. 계층적 군집 단계별 진행

- 가장 유사한 두 클러스터를 병합한다.
- 한개의 단일 클러스터가 될 때까지 진행한다
- 매 단계에서 모든 클러스터 쌍 간의 거리를 계산해야하기 때문에 데이터의 수가 많은 경우, K-means에 비하여 계산량이 많다.

### 4-4. 계층적 군집의 링크 유형

**최소 거리 링크**
- 두개 클러스터 내 데이터 쌍별 거리 중 최소값을 군집 간 거리로

최대 거리 링크, 평균 거리 링크도 있음.

### 4-5. 링크 유형에 따른 계층적 군집 결과

링크에 따라 결과가 달라진다!

같은 데이터라도 링크 선택에 따라 클러스터링 결과가 달라질 수 있음

## 5. 클러스터링시 주의점

단일 시도가 아닌 여러 번 시도하는 것을 권장
