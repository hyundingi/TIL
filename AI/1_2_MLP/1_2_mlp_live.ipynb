{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor\n",
    "\n",
    "numpyì˜ ndarray ì²˜ëŸ¼ ì—¬ëŸ¬ ë°ì´í„°ë¥¼ ë™ì‹œì— ë‹¤ë£¨ë©° PyTorchì˜ autograd ë“± ë¨¸ì‹ ëŸ¬ë‹ì— ë„ì›€ë˜ëŠ” ê¸°ëŠ¥ì„ ê°€ì§€ê³  ìˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 99,
     "status": "ok",
     "timestamp": 1760501610258,
     "user": {
      "displayName": "jeeho park",
      "userId": "02090712094119266150"
     },
     "user_tz": -540
    },
    "id": "WQJVZn7igskI",
    "outputId": "632d0209-7d88-4ff9-8672-ab811e90529c"
   },
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "\"\"\"\n",
    "torchì˜ í…ì„œ\n",
    "\"\"\"\n",
    "x = torch.rand(3, 3)\n",
    "y = torch.ones(3, 3)\n",
    "print(x)\n",
    "print(x.T)\n",
    "print(y)\n",
    "print(x + y)\n",
    "print(x @ y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1760501610264,
     "user": {
      "displayName": "jeeho park",
      "userId": "02090712094119266150"
     },
     "user_tz": -540
    },
    "id": "kOb03zaphosY",
    "outputId": "4996e0a2-2802-41c4-8986-45c3de3b6661"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ì—­ì „íŒŒ: backward\n",
    "\"\"\"\n",
    "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "y = x ** 2 + 3 * x + 1\n",
    "z = y.sum()\n",
    "# back propagation\n",
    "z.backward()\n",
    "# ì—­ì „íŒŒëœ ê¸°ìš¸ê¸°ëŠ” .gradì—ì„œ í™•ì¸ ê°€ëŠ¥\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì‹¤ìŠµ ì¤€ë¹„\n",
    "\n",
    "ì¥ì¹˜ ì„¤ì • ë° ë‚œìˆ˜ ê³ ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1760501610295,
     "user": {
      "displayName": "jeeho park",
      "userId": "02090712094119266150"
     },
     "user_tz": -540
    },
    "id": "A-UA3mOJjAPx",
    "outputId": "7825d2d9-e7ea-4017-f236-846716a505cf"
   },
   "outputs": [],
   "source": [
    "# ì¥ì¹˜ ê´€ë¦¬\n",
    "device = 'cpu'\n",
    "# windows - cuda\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "# apple silicon - mps\n",
    "if torch.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "print(device)\n",
    "\n",
    "# x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1760501610347,
     "user": {
      "displayName": "jeeho park",
      "userId": "02090712094119266150"
     },
     "user_tz": -540
    },
    "id": "P8L6GSa2kOQW"
   },
   "outputs": [],
   "source": [
    "# ë‚œìˆ˜ ê³ ì •\n",
    "import numpy as np\n",
    "import random\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# windows - cuda\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# apple silicon - mps\n",
    "if torch.mps.is_available():\n",
    "    torch.mps.manual_seed(SEED)\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorchë¡œ ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„ í˜• íšŒê·€ ëª¨ë¸ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 171,
     "status": "ok",
     "timestamp": 1760501610517,
     "user": {
      "displayName": "jeeho park",
      "userId": "02090712094119266150"
     },
     "user_tz": -540
    },
    "id": "NF16g-u2lICO",
    "outputId": "64ea9e80-464d-4cbf-a7f8-566aea5c2b20"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ì„ í˜• íšŒê·€ ëª¨ë¸ì„ PyTorchë¡œ êµ¬í˜„\n",
    "\"\"\"\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "# ë”ë¯¸ ë°ì´í„° ìƒì„±\n",
    "X = torch.linspace(0, 10, 100).unsqueeze(1)\n",
    "y_true = 2 * X + 1 + 0.5 * torch.randn_like(X)\n",
    "\n",
    "# 1ì°¨ì› ì…ë ¥, 1ì°¨ì› ì¶œë ¥ì˜ ì„ í˜• ëª¨ë¸ì„ ë§Œë“¤ê²ƒì´ë‹¤\n",
    "model = nn.Linear(1, 1)\n",
    "# ë¹„ìš© í•¨ìˆ˜ëŠ” MSEë¥¼ ì“¸ê±°ë‹¤\n",
    "criterion = nn.MSELoss()\n",
    "# SGDë¡œ íŒŒë¼ë¯¸ëŸ¬ë¥¼ ê°±ì‹ í• ê±°ë‹¤\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# í•™ìŠµ ì‹œì‘\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    # ê¸°ìš¸ê¸° ì´ˆê¸°í™”\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # ì˜ˆì¸¡ ì§„í–‰\n",
    "    y_pred = model(X)\n",
    "    # ì†ì‹¤ ê³„ì‚°\n",
    "    loss = criterion(y_pred, y_true)\n",
    "    # ë¹„ìš©ì˜ ë¯¸ë¶„ ê³„ì‚°\n",
    "    loss.backward()\n",
    "    # ë§¤ê°œë³€ìˆ˜ ì—…ë°ì´íŠ¸\n",
    "    optimizer.step()\n",
    "    # 20ë²ˆì˜ í•™ìŠµë§ˆë‹¤ ê¸°ë¡\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('í•™ìŠµëœ ê°€ì¤‘ì¹˜ + í¸í–¥')\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'{name}: {param.data}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "executionInfo": {
     "elapsed": 429,
     "status": "ok",
     "timestamp": 1760501610958,
     "user": {
      "displayName": "jeeho park",
      "userId": "02090712094119266150"
     },
     "user_tz": -540
    },
    "id": "tyMjkVv0lunt",
    "outputId": "e779c3cd-93b8-405d-dbf2-66c031289f2d"
   },
   "outputs": [],
   "source": [
    "# ì‹¤ì œ ë°ì´í„°ì™€ íšŒê·€ì„  ë¹„êµ\n",
    "def show_data():\n",
    "    X_np = X.squeeze().numpy()\n",
    "    y_true_np = y_true.squeeze().numpy()\n",
    "    w_learned = model.weight.item()\n",
    "    b_learned = model.bias.item()\n",
    "    print(w_learned, b_learned)\n",
    "    y_line_np = w_learned * X_np + b_learned\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X_np, y_true_np, s=20, color='b', alpha=0.6, label='Synthetic Data')\n",
    "    plt.plot(X_np, y_line_np, color='red', linewidth=2, label=f'Learned Model')\n",
    "\n",
    "    plt.title('Dummy Data')\n",
    "    plt.xlabel('X (Feature)')\n",
    "    plt.ylabel('y_true (Label)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "show_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1760501610982,
     "user": {
      "displayName": "jeeho park",
      "userId": "02090712094119266150"
     },
     "user_tz": -540
    },
    "id": "6EZxx731oYHa",
    "outputId": "d2a9d43c-e0a2-456b-bfba-8d30ae13e35e"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ì…ë ¥ - ì€ë‹‰ - ì¶œë ¥ êµ¬ì¡°ì˜ MLP ë§Œë“¤ê¸°\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# ì–´ë–¤ ê³„ì¸µì„ ë„£ì„ì§€ë¥¼ ê²°ì •í•´ì„œ ì¸µ êµ¬ì¡°ë¥¼ classë¡œ ì •ì˜\n",
    "class SimpleMLP(nn.Module):  # __call__\n",
    "    # ê° ì¸µì˜ ë‰´ëŸ°ì˜ ê°¯ìˆ˜ëŠ” ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë§Œë“¤ë•Œ ê²°ì •\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    # nn.Module()ì˜ __call__ì´ í˜¸ì¶œë  ë•Œ ìë™ìœ¼ë¡œ í˜¸ì¶œ\n",
    "    def forward(self, x):\n",
    "        # ê° ì¸µì„ ìˆœì°¨ì ìœ¼ë¡œ í˜¸ì¶œ\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SequentialMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        # ê° ì¸µì„ ìˆœì°¨ì ìœ¼ë¡œ ìŒ“ëŠ”ë‹¤.\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "model = SimpleMLP(20, 10, 1)\n",
    "# 20ê°œì˜ featureë¥¼ ê°€ì§„ 40ê°œì˜ ë°ì´í„°\n",
    "X = torch.rand(size=(40, 20))\n",
    "# ëª¨ë¸ì„ ì´ìš©í•´ ì˜ˆì¸¡í•˜ê¸°\n",
    "y_pred = model(X)\n",
    "# 40ê°œì˜ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ì¶œë ¥ 1ê°œì”© 40ì¤„\n",
    "print(y_pred.size())\n",
    "y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ìˆ«ì íŒë…ê¸° ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "executionInfo": {
     "elapsed": 9330,
     "status": "ok",
     "timestamp": 1760501620310,
     "user": {
      "displayName": "jeeho park",
      "userId": "02090712094119266150"
     },
     "user_tz": -540
    },
    "id": "-IFNkWtvs6Z-",
    "outputId": "936f9f13-3fc0-4cb6-ebc5-84b5cae9e44c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data.astype(np.float32)\n",
    "y = digits.target.astype(np.int64)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13, 5), nrows=2, ncols=5)\n",
    "for i in range(10):\n",
    "    ax[i // 5, i % 5].imshow(X[i].reshape(8, 8), cmap=\"gray\")\n",
    "    ax[i // 5, i % 5].set_title(f\"Label: {y[i]}\")\n",
    "    ax[i // 5, i % 5].axis(\"off\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í•™ìŠµ / ê²€ì¦ ë°ì´í„° ë¶„ë¦¬ ë° í‘œì¤€í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1760502051921,
     "user": {
      "displayName": "jeeho park",
      "userId": "02090712094119266150"
     },
     "user_tz": -540
    },
    "id": "smOvuHV5E3dB"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 1. ë°ì´í„°ë¥¼ ë¶„í• í•˜ê³  í‘œì¤€í™”í•´ì¤ë‹ˆë‹¤.\n",
    "# ì´ë²ˆì—ëŠ” ê²€ì¦ë°ì´í„° (X_valid)ê³¼ í…ŒìŠ¤íŠ¸ë°ì´í„° (X_test)ê¹Œì§€ ë§Œë“¤ì–´ì¤ì‹œë‹¤.\n",
    "# X_testëŠ” ì‹¤ì œë¡œ ì •ë‹µì´ ì—†ëŠ” ì²˜ìŒ ë³´ëŠ” ë°ì´í„°ë¡œ ìµœì¢… ì„±ëŠ¥ì„ í™•ì¸í•´ì•¼í•  ë°ì´í„°,\n",
    "# X_valì€ ì¤‘ê°„ì¤‘ê°„ ëª¨ë¸ì˜ ê²€ì¦ê²°ê³¼ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•œ ë°ì´í„°ì…ë‹ˆë‹¤.\n",
    "# í•™ìŠµë°ì´í„°ëŠ” ì „ì²´ì˜ 80%, ë‚˜ë¨¸ì§€ ê²€ì¦ê³¼ í…ŒìŠ¤íŠ¸ë°ì´í„°ëŠ” ê°ê° 10%ì”© í• ë‹¹í•´ì£¼ì„¸ìš”.\n",
    "# ë‚œìˆ˜ëŠ” ìœ„ì—ì„œ ì •ì˜ëœ `SEED`ë¥¼ í™œìš©í•´ì£¼ì„¸ìš”.\n",
    "# stratify í•˜ëŠ”ê²ƒë„ ìŠì§€ ë§ˆì‹œêµ¬ìš”.\n",
    "from sklearn.model_selection import train_test_split\n",
    "# ìš°ì„  8:2ë¡œ ë‚˜ëˆ„ê³ \n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "# ë‚¨ì€ 2ë¥¼ 1:1ë¡œ ë‚˜ëˆ„ì\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=SEED, stratify=y_temp\n",
    ")\n",
    "\n",
    "# í‘œì¤€í™”\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasetê³¼ DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1760502446952,
     "user": {
      "displayName": "jeeho park",
      "userId": "02090712094119266150"
     },
     "user_tz": -540
    },
    "id": "61chpbC8GXJB"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 2. PyTorch Datasetì„ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤\n",
    "# batch ì²˜ë¦¬ë°©ì‹ì„ ê¸°ì–µí•˜ì‹œë‚˜ìš”?\n",
    "# ë§¤ë²ˆ Xì—ì„œ ì¸ë±ì‹±ì„ í†µí•´ ë°ì´í„°ë¥¼ ë°°ì¹˜ë¡œ ë½‘ì•„ëƒˆìŠµë‹ˆë‹¤.\n",
    "# ì—¬ê°„ ê·€ì°®ì€ê²Œ ì•„ë‹ˆì—ˆëŠ”ë°ìš”, ì´ë¥¼ ê°„í¸í•˜ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” ë°©ì‹ì´ PyTorchì— ì¡´ì¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "# TODO:\n",
    "# ëª¨ë“  ë°ì´í„°ë¥¼ í…ì„œë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”\n",
    "X_train_t = torch.from_numpy(X_train)\n",
    "y_train_t = torch.from_numpy(y_train)\n",
    "X_valid_t = torch.from_numpy(X_valid)\n",
    "y_valid_t = torch.from_numpy(y_valid)\n",
    "X_test_t  = torch.from_numpy(X_test)\n",
    "y_test_t  = torch.from_numpy(y_test)\n",
    "\n",
    "# TODO:\n",
    "# Pytorch TensorDatasetì— ë„£ì–´ì¤ì‹œë‹¤.\n",
    "# https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset\n",
    "\n",
    "# í•˜ë‚˜ì˜ ë°ì´í„°ì˜ ê¸°ì¤€\n",
    "# - TensorDataset: indexë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•˜ë‚˜ì˜ ìƒ˜í”Œ ë°ì´í„°ë¥¼ êµ¬ë¶„\n",
    "from torch.utils.data import TensorDataset\n",
    "train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "valid_ds = TensorDataset(X_valid_t, y_valid_t)\n",
    "test_ds  = TensorDataset(X_test_t, y_test_t)\n",
    "\n",
    "# TODO:\n",
    "# ìœ„ì—ì„œ ë§Œë“  TensorDatasetì„ DataLoaderë¡œ ë³€í™˜ì‹œì¼œì¤ë‹ˆë‹¤.\n",
    "# ë‘˜ì˜ ì°¨ì´ë¥¼ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•˜ìë©´\n",
    "#   - Dataset: ë°ì´í„° í•˜ë‚˜ë¥¼ ì–´ë–»ê²Œ ì½ì–´ì˜¬ì§€ ì •ì˜\n",
    "#   - DataLoader: ë°°ì¹˜ì²˜ë¦¬ë¥¼ ì–´ë–»ê²Œí• ì§€ ì •ì˜\n",
    "# ë”°ë¼ì„œ DataLoaderëŠ” batch_sizeë¥¼ ì •ì˜í•´ì¤˜ì•¼í•©ë‹ˆë‹¤.\n",
    "# ì•„ë˜ ì„¤ì ›ì• ë‘” BATCH_SIZEë¥¼ í™œìš©í•´ì£¼ì„¸ìš”.\n",
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1760502447786,
     "user": {
      "displayName": "jeeho park",
      "userId": "02090712094119266150"
     },
     "user_tz": -540
    },
    "id": "DJYZAcnhH1aI",
    "outputId": "2bbfc341-f6bd-4a57-9e8a-899b9065c767"
   },
   "outputs": [],
   "source": [
    "for idx, batch in enumerate(train_loader):\n",
    "    print(idx, batch)\n",
    "    print(len(batch[1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1760503055485,
     "user": {
      "displayName": "jeeho park",
      "userId": "02090712094119266150"
     },
     "user_tz": -540
    },
    "id": "Yrz4qonIH3HW"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 3. Multi-Layer Perceptron êµ¬í˜„í•˜ê¸°\n",
    "# ê°€ì¥ ê¸°ë³¸ì ì¸ MultiLayer Perceptronì„ êµ¬í˜„í•´ì£¼ì„¸ìš”.\n",
    "# ê³„ì¸µì€ ì´ 3ê°œì…ë‹ˆë‹¤.\n",
    "# ì…ë ¥í‘œí˜„ -> ì€ë‹‰í‘œí˜„1 -> ì€ë‹‰í‘œí˜„2 -> ì¶œë ¥í‘œí˜„\n",
    "# ì…ë ¥ê°’ë“¤ì€ `nn.Linear`ë¥¼ í†µê³¼í•œ ë’¤ ReLUë¥¼ ê±°ì¹˜ê³  Dropoutì„ ê±°ì¹˜ë„ë¡ ì„¤ê³„í•´ì£¼ì„¸ìš”.\n",
    "# ì œê°€ ì •ì˜í•´ì¤€ `__init__` ì•ˆì˜ ì¸ìì— ë§ì¶°ì„œ ì‘ì—…í•´ì£¼ì„¸ìš” :)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 num_classes: int,\n",
    "                 hidden_dims=(128, 64),\n",
    "                 dropout=0.2):\n",
    "        super().__init__()\n",
    "        h1, h2 = hidden_dims\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            # ì€ë‹‰1\n",
    "            nn.Linear(input_dim, h1),\n",
    "            # í™œì„±í™” + Dropout\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            # ì€ë‹‰2 (ì…ë ¥ ì°¨ì›ì€ ì€ë‹‰1ì˜ ì¶œë ¥ì°¨ì›)\n",
    "            nn.Linear(h1, h2),\n",
    "            # í™œì„±í™” + Dropout\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            # ì¶œë ¥\n",
    "            nn.Linear(h2, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í•™ìŠµ ë° í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1760503174846,
     "user": {
      "displayName": "jeeho park",
      "userId": "02090712094119266150"
     },
     "user_tz": -540
    },
    "id": "aLu26CSdKMPM"
   },
   "outputs": [],
   "source": [
    "# ì •ë‹µì½”ë“œ\n",
    "# 4. DataLoader, Model, Optimizerê°€ ì£¼ì–´ì¡Œì„ ë•Œ\n",
    "# í•™ìŠµë°ì´í„°ì— ëŒ€í•´ modelì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "def train_one_epoch(model, loader, optimizer, device):\n",
    "    # ëª¨ë¸ì´ í•™ìŠµëª¨ë“œë¡œ ë“¤ì–´ê°€ê²Œ ì„¤ì •í•´ì•¼í•©ë‹ˆë‹¤.\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for xb, yb in loader:\n",
    "        # ë°ì´í„°ë¥¼ ê°€ì†í™”ê¸°ê¸°ë¡œ ë³´ë‚´ì£¼ì„¸ìš”.\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        # ìœ„ì—ì„œ ë°°ìš´ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ ë°©ì‹ì„ êµ¬í˜„í•´ì£¼ì„¸ìš”.\n",
    "        # 1. ëª¨ë¸ì˜ ì¶œë ¥ ë§Œë“¤ì–´ì£¼ê¸°\n",
    "        # 2. ë¯¸ë¶„ê°’ ì§€ì›Œì£¼ê¸° (zero_grad)\n",
    "        # 3. Loss ê³„ì‚°í•´ì£¼ê¸°: lossëŠ” cross_entropyë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”\n",
    "        #   - https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html\n",
    "        # 4. 3ì—ì„œ ê³„ì‚°í•œ Lossë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì—­ì „íŒŒë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "        # 5. íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ë¥¼ ì§„í–‰í•´ì£¼ì„¸ìš”\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ê°€ ëë‚¬ìœ¼ë©´ ëª‡ ê°€ì§€ë¥¼ ê¸°ë¡í•´ì¤ë‹ˆë‹¤.\n",
    "        # 1. batchë‹¹ ë¡œìŠ¤ ê³„ì‚° (running_lossì— ì—…ë°ì´íŠ¸)\n",
    "        # 2. ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ê³„ì‚° (`preds`)\n",
    "        # 3. batch ë‚´ ì •í™•ë„ ê³„ì‚° (batch ë‚´ì—ì„œ ì •ë‹µê°œìˆ˜ë¥¼ correctì— ì¶”ê°€)\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "\n",
    "    # ìœ„ì—ì„œ ì˜ ê³„ì‚°ëœ ê°’ë“¤ì„ ì •ë¦¬í•´ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    avg_loss = running_loss / total\n",
    "    acc = correct / total\n",
    "    return avg_loss, acc\n",
    "\n",
    "# ì •ë‹µì½”ë“œ\n",
    "# 5. ì´ë²ˆì—ëŠ” ëª¨ë¸ê³¼ ê²€ì¦/í…ŒìŠ¤íŠ¸ë°ì´í„°ê°€ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ì™”ì„ ë•Œ ì •í™•ë„ë¥¼ ê³„ì‚°í•´ì£¼ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "def evaluate(model, loader, device):\n",
    "    # ëª¨ë¸ì´ ì¶”ë¡ í•  ë•ŒëŠ” ì¶”ë¡ ëª¨ë“œë¡œ ì„¤ì •í•´ì£¼ì–´ì•¼í•©ë‹ˆë‹¤.\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    # ë¯¸ë¶„ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ì§€ ì•Šë„ë¡ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì…”ì•¼í•©ë‹ˆë‹¤.\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            # ë°ì´í„°ë¡œë”ì—ì„œ ë‚˜ì˜¨ ë°°ì¹˜ë¥¼ `device`ë¡œ ë³´ë‚´ì£¼ì„¸ìš”.\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "            # ìœ„ì—ì„œ í•œ ê²ƒê³¼ ë¹„ìŠ·í•˜ê²Œ\n",
    "            # ëª¨ë¸ì˜ ì¶œë ¥ê°’ì„ ë§Œë“¤ì–´ `logits`ì— ë‹´ê³ \n",
    "            # í˜„ì¬ ì¶œë ¥ê°’ `logits`ì™€ `yb` ì‚¬ì´ì˜ Cross Entropyë¥¼ ê³„ì‚°í•´ì£¼ì„¸ìš”.\n",
    "            logits = model(xb)\n",
    "            loss = torch.nn.functional.cross_entropy(logits, yb)\n",
    "\n",
    "            # ì´ë²ˆì—ë„ ë‹¤ìŒì„ ê¸°ë¡í•´ì¤ë‹ˆë‹¤.\n",
    "            # 1. batchë‹¹ ë¡œìŠ¤ ê³„ì‚° (running_lossì— update)\n",
    "            # 2. ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ê³„ì‚° (`preds`)\n",
    "            # 3. batch ë‚´ ì •í™•ë„ ê³„ì‚° (batch ë‚´ì—ì„œ ì •ë‹µê°œìˆ˜ë¥¼ correctì— ì¶”ê°€)\n",
    "            # 4. í›„ì— ì •í™•í•œ ë¶„ë¥˜ì„±ëŠ¥ì„ ë³´ê¸° ìœ„í•´ prediction ê°’ë“¤ë„ ì „ë¶€ ê¸°ë¡í•´ì¤ë‹ˆë‹¤.\n",
    "            #  - all_preds, all_targetsì— appendí•´ì¤ë‹ˆë‹¤.\n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_targets.append(yb.cpu())\n",
    "\n",
    "    # ìœ„ì—ì„œ ì˜ ê³„ì‚°ëœ ê°’ë“¤ì„ ì •ë¦¬í•´ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    avg_loss = running_loss / total\n",
    "    acc = correct / total\n",
    "    preds_cat = torch.cat(all_preds).numpy()\n",
    "    targets_cat = torch.cat(all_targets).numpy()\n",
    "    return avg_loss, acc, preds_cat, targets_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6823,
     "status": "ok",
     "timestamp": 1760503223279,
     "user": {
      "displayName": "jeeho park",
      "userId": "02090712094119266150"
     },
     "user_tz": -540
    },
    "id": "D_pKXUZ0KpYN",
    "outputId": "c1742d3d-e12a-48e7-d827-a980610a8041"
   },
   "outputs": [],
   "source": [
    "# ëª¨ë“  ê²ƒì„ í•˜ë‚˜ë¡œ!\n",
    "# ì—¬ëŸ¬ë¶„ì´ ì½”ë“œë¥¼ ì˜ ì§°ë‹¤ë©´ ì•„ë˜ ì½”ë“œê°€ ì˜ ì‘ë™í• ê²ë‹ˆë‹¤!\n",
    "# ì—ëŸ¬ê°€ ëœ¬ë‹¤ë©´ ì—ëŸ¬ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ì„œ ì˜ êµ¬í˜„ë˜ë„ë¡ ë§ì¶°ì£¼ì„¸ìš”.\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# device = torch.device(\"cuda\")\n",
    "model = MLP(\n",
    "    input_dim=64,\n",
    "    num_classes=10,\n",
    "    hidden_dims=(128, 64),\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "# ì´ë²ˆì—ëŠ” ì§€ë‚œ ê³¼ì œ2ì—ì„œ ë°°ì› ë˜ Adamì„ ì‚¬ìš©í•´ë´…ì‹œë‹¤.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "best_val_loss = math.inf\n",
    "best_val_acc = -1.0\n",
    "epochs_no_improve = 0\n",
    "\n",
    "checkpoint_path = \"model.ckpt\"\n",
    "earlystop_patience = 5\n",
    "\n",
    "train_losses, train_accs = [], []\n",
    "valid_losses, valid_accs = [], []\n",
    "for epoch in range(1, 201):\n",
    "    t0 = time.time()\n",
    "    # ì—¬ëŸ¬ë¶„ì´ ì •ì˜í•œ `train_one_epoch`ì™€ `evaluate`ì…ë‹ˆë‹¤.\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    val_loss, val_acc, _, _ = evaluate(model, valid_loader, device)\n",
    "    valid_losses.append(val_loss)\n",
    "    valid_accs.append(val_acc)\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(\n",
    "        f\"Epoch {epoch:03d} | \"\n",
    "        f\"train loss {train_loss:.4f} acc {train_acc*100:5.2f}% | \"\n",
    "        f\"val loss {val_loss:.4f} acc {val_acc*100:5.2f}% | \"\n",
    "        f\"{dt:.1f}s\"\n",
    "    )\n",
    "\n",
    "    # ğŸŒŸ ê°œì„  ì‹œ ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n",
    "    improved = (val_loss < best_val_loss) or (val_acc > best_val_acc)\n",
    "    if improved:\n",
    "        best_val_loss = min(best_val_loss, val_loss)\n",
    "        best_val_acc = max(best_val_acc, val_acc)\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'input_dim': 64,\n",
    "            'num_classes': 10,\n",
    "        }, checkpoint_path)\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    # ì¡°ê¸° ì¢…ë£Œ\n",
    "    if epochs_no_improve >= earlystop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} (no improve {earlystop_patience})\")\n",
    "        break\n",
    "\n",
    "# ë² ìŠ¤íŠ¸ ëª¨ë¸ ë¡œë“œ í›„ í…ŒìŠ¤íŠ¸ í‰ê°€\n",
    "if os.path.exists(checkpoint_path):\n",
    "    ckpt = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(ckpt['model_state_dict'])\n",
    "    print(f\"Loaded best checkpoint: val_best_acc={best_val_acc*100:.2f}% val_best_loss={best_val_loss:.4f}\")\n",
    "\n",
    "test_loss, test_acc, y_pred, y_true = evaluate(model, test_loader, device)\n",
    "print(\"\\n==== Test Result ====\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test acc : {test_acc*100:.2f}%\")\n",
    "\n",
    "# ë¶„ë¥˜ ë¦¬í¬íŠ¸ / í˜¼ë™í–‰ë ¬\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_D4q7RUKziU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPpA/iin3qUguOhmhGKzelL",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
